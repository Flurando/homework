#+TITLE: Linear Algebra Assignment 4
#+AUTHOR: 2024110144
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper,12pt]
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \pdfcompresslevel=9
#+OPTIONS: \n:t toc:nil num:nil date:nil

#+begin_center
Please submit by 5:00 PM on May 2rd to the email address: 2592793289@qq.com
#+end_center

* Problem 1
In $\mathbb{R}^4$, let
$$v_1=(1,1,1,1),\quad v_2=(2,1,-1,0),\quad v_3=(0,2,1,3),\quad v_4=(1,-2,3,4).$$
Prove that ${v_1,v_2,v_3,v_4} is a linearly independent set.
** Solution 1
for the equation
$$c_1v_1+c_2v_2+c_3v_3+c_4v_4=(0,0,0,0)$$
so we have the equations as
$$\begin{align*}
& c_1 + 2c_2 + c_4 &= 0\\
& c_1 + c_2 + 2c_3 - 2c_4 &= 0\\
& c_1 - c_2 + c_3 + 3c_4 &= 0\\
& c_1 + 3c_3 + 4c_4 &= 0
\end{align*}$$
adding the second and third equation
we get
$$ 2c_1 + 3c_3 + c_4 = 0 $$
then we substract the fourth one from it
$$ c_1 - 3c_4 = 0 $$
so $c_1=3c_4$
suppose $c_1=c$ then $c_4=3c$
and from the first equation we have $c_2=-2c$
furthermore we have $c_3=-12c$ from the third
and $c_3=3.5c$ from the fourth
so $c=0$
which means $c_1=c_2=c_3=c_4=0$ as the only solution
this is trival
so they are linearly independent

* Problem 2
Consider the $3\times 3$ matrix
$$A=\left(\begin{matrix}
1  & 2  & 3\\
2  & 4  & 6\\
-1 & -1 & 0
\end{matrix}\right)$$.
1. Compute $det(A)$ by any method you prefer (e.g., expansion, row operations, etc.).
2. Based on the value of $det(A)$, determine whether the columns of $A$ are linearly independent or dependent.
3. Briefly explain how the determinant relates to linear independence.
** Solution 2
*** 1
$$\left(\begin{matrix}
1  & 2  & 3\\
2  & 4  & 6\\
-1 & -1 & 0
\end{matrix}\right)$$
$$\left(\begin{matrix}
1  & 2  & 3\\
0  & 0  & 0\\
-1 & -1 & 0
\end{matrix}\right)$$
$$\left(\begin{matrix}
1  & 2  & 3\\
-1 & -1 & 0\\
0  & 0  & 0
\end{matrix}\right)$$
$$\left(\begin{matrix}
1 & 2 & 3\\
0 & 1 & 0\\
0 & 0 & 0
\end{matrix}\right)$$
so $det(A)=0$
*** 2
since it is zero, they are linearly dependent
*** 3
the determinant would be zero when linearly dependent
nonzero when linearly independent
this is because when determinant is zero,
we can always use row operations to make a row to be all zeros
* Problem 3
Let $P_2(\mathbb{R})$ be the vector space of real polynomials of degree at most $2$. Consider the standard basis $\epsilon = {1,x,x^2}$ and another basis $\beta = {1+x, x+x^2, 1+x^2}$.
1. For $p(x) = 2+3x-x^2$, find its coordinate vector $[p]_{\beta}.
2. Find the transition matrix from $\epsilon$ to $\beta$.
3. Let $q(x) = x+2x^2$. Compute $[q]_{\beta}$.
** Solution 3
*** 1
suppose $p(x)=a(1+x)+b(x+x^2)+c(1+x^2)$
which means
$$\begin{align*}
a + c &= 2\\
a + b &= 3\\
b + c &= -1
\end{align*}$$
so we have the coordinate vector as $\left(\begin{matrix}3\\0\\-1\end{matrix}\right)$
*** 2
$$\begin{align*}
1+x &= a+bx+cx^2\\
x+x^2 &= d+ex+fx^2\\
1+x^2 &= g+hx+ix^2
\end{align*}$$
so the transition matrix is
$$\begin{bmatrix}
1 & 1 & 0\\
0 & 1 & 1\\
1 & 0 & 1
\end{bmatrix}$$
*** 3
we know $[q]_{\epsilon}=\left(\begin{matrix}0\\1\\2\end{matrix}\right)$
then we have
$$\begin{aligned}
[q]_{\beta} &= \begin{bmatrix}
1 & 1 & 0\\
0 & 1 & 1\\
1 & 0 & 1
\end{bmatrix} \cdot \left(\begin{matrix}0\\1\\2\end{matrix}\right)\\
&= \left(\begin{matrix}1\\3\\2\end{matrix}\right)
\end{aligned}$$
* Problem 4
Let $U$ and $V$ be subspaces of a vector space $W$. Recall the definition
$$ U+V = { z | z=u+v, u \in U, v \in V } $$
Suppose $dim(U)=3$ and $dim(V)=4$.
1. Prove that $U+V$ is a subspace of $W$.
2. If $dim(U \cap V)=2$, determine $dim(U+V)$. (Hint: use the formula $dim(U+V)=dim(U)+dim(V)-dim(U \cap V)$).
** Solution 4
*** 1
Suppose the statement is not true
we know there exists a $w \in W$ so that
$w$ does not belong to $U+V$
*** 2
* Problem 5
Let
$$B=\left(\begin{matrix}
1  & 3  & 0 & 2\\
2  & 6  & 1 & 4\\
-1 & -3 & 2 & 0\\
0  & 0  & 1 & 1
\end{matrix}\right)$$.
1. Find the basis for the null space of $B$.
2. Determine the dimension of the columne space of $B$.
3. Verify the Rank-Nullity Theorem for this matrix.
